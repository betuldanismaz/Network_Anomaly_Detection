{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“‚ Data Path: D:\\Projects\\networkdetection\\networkdetection\\data\\processed_randomforest\\train.csv\n",
            "ğŸ“Š Results Dir: D:\\Projects\\networkdetection\\networkdetection\\experiments\\results\n",
            "ğŸ¤– Models Dir: D:\\Projects\\networkdetection\\networkdetection\\models\n",
            "âœ… Configuration loaded!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configuration\n",
        "RANDOM_STATE = 42\n",
        "SAMPLE_SIZE = 200_000\n",
        "TARGET_COLUMN = 'Label'\n",
        "\n",
        "# Paths\n",
        "PROJECT_ROOT = Path('..').resolve()\n",
        "DATA_PATH = PROJECT_ROOT / 'data' / 'processed_randomforest' / 'train.csv'\n",
        "RESULTS_DIR = PROJECT_ROOT / 'experiments' / 'results'\n",
        "MODELS_DIR = PROJECT_ROOT / 'models'\n",
        "\n",
        "# Ensure output directories exist\n",
        "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"ğŸ“‚ Data Path: {DATA_PATH}\")\n",
        "print(f\"ğŸ“Š Results Dir: {RESULTS_DIR}\")\n",
        "print(f\"ğŸ¤– Models Dir: {MODELS_DIR}\")\n",
        "print(f\"âœ… Configuration loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â³ Loading dataset (this may take a moment for large files)...\n",
            "âœ… Dataset loaded! Shape: (1306484, 21)\n",
            "   Total samples: 1,306,484\n",
            "   Features: 20\n",
            "   Target: 'Label'\n"
          ]
        }
      ],
      "source": [
        "# Load the pre-processed dataset\n",
        "print(\"â³ Loading dataset (this may take a moment for large files)...\")\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(f\"âœ… Dataset loaded! Shape: {df.shape}\")\n",
        "print(f\"   Total samples: {df.shape[0]:,}\")\n",
        "print(f\"   Features: {df.shape[1] - 1}\")\n",
        "print(f\"   Target: '{TARGET_COLUMN}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Original Class Distribution:\n",
            "==================================================\n",
            "  Class 0:  1,078,393 samples ( 82.54%)\n",
            "  Class 1:    228,091 samples ( 17.46%)\n",
            "\n",
            "  Total: 1,306,484 samples\n"
          ]
        }
      ],
      "source": [
        "# Display original class distribution\n",
        "print(\"\\nğŸ“Š Original Class Distribution:\")\n",
        "print(\"=\" * 50)\n",
        "class_dist = df[TARGET_COLUMN].value_counts().sort_index()\n",
        "class_pct = df[TARGET_COLUMN].value_counts(normalize=True).sort_index() * 100\n",
        "\n",
        "for label, count in class_dist.items():\n",
        "    pct = class_pct[label]\n",
        "    print(f\"  Class {label}: {count:>10,} samples ({pct:>6.2f}%)\")\n",
        "\n",
        "print(f\"\\n  Total: {df.shape[0]:,} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âš¡ Creating stratified sample of 200,000 rows...\n",
            "âœ… Stratified sample created! Shape: (200000, 21)\n"
          ]
        }
      ],
      "source": [
        "# Strategic Sampling with Stratification\n",
        "print(f\"\\nâš¡ Creating stratified sample of {SAMPLE_SIZE:,} rows...\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[TARGET_COLUMN])\n",
        "y = df[TARGET_COLUMN]\n",
        "\n",
        "# Calculate sample fraction\n",
        "sample_frac = SAMPLE_SIZE / len(df)\n",
        "\n",
        "# Stratified sampling using train_test_split\n",
        "# We take SAMPLE_SIZE as our \"train\" portion\n",
        "X_sample, _, y_sample, _ = train_test_split(\n",
        "    X, y,\n",
        "    train_size=SAMPLE_SIZE,\n",
        "    stratify=y,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "# Combine back into single DataFrame for PyCaret\n",
        "df_sample = pd.concat([X_sample, y_sample], axis=1).reset_index(drop=True)\n",
        "\n",
        "print(f\"âœ… Stratified sample created! Shape: {df_sample.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ” Sample Class Distribution (Integrity Check):\n",
            "============================================================\n",
            "Class             Count     Sample %   Original %        Î”\n",
            "------------------------------------------------------------\n",
            "0               165,083       82.54%       82.54%  -0.000%\n",
            "1                34,917       17.46%       17.46%  +0.000%\n",
            "------------------------------------------------------------\n",
            "Total           200,000\n",
            "\n",
            "âœ… Stratification preserved! Class proportions maintained.\n"
          ]
        }
      ],
      "source": [
        "# Verify stratification integrity\n",
        "print(\"\\nğŸ” Sample Class Distribution (Integrity Check):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "sample_dist = df_sample[TARGET_COLUMN].value_counts().sort_index()\n",
        "sample_pct = df_sample[TARGET_COLUMN].value_counts(normalize=True).sort_index() * 100\n",
        "original_pct = class_pct\n",
        "\n",
        "print(f\"{'Class':<10} {'Count':>12} {'Sample %':>12} {'Original %':>12} {'Î”':>8}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for label in sample_dist.index:\n",
        "    count = sample_dist[label]\n",
        "    s_pct = sample_pct[label]\n",
        "    o_pct = original_pct[label]\n",
        "    delta = s_pct - o_pct\n",
        "    print(f\"{label:<10} {count:>12,} {s_pct:>11.2f}% {o_pct:>11.2f}% {delta:>+7.3f}%\")\n",
        "\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Total':<10} {df_sample.shape[0]:>12,}\")\n",
        "print(\"\\nâœ… Stratification preserved! Class proportions maintained.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ§¹ Memory cleaned: Original dataset removed from memory.\n"
          ]
        }
      ],
      "source": [
        "# Free up memory from original dataset\n",
        "del df, X, y\n",
        "import gc\n",
        "gc.collect()\n",
        "print(\"ğŸ§¹ Memory cleaned: Original dataset removed from memory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ Initializing PyCaret Classification Environment...\n",
            "   GPU Mode: DISABLED (Intel OpenCL Issue)\n",
            "   Normalization: ENABLED\n",
            "   Session ID: 42 (Reproducibility)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from pycaret.classification import (\n",
        "    setup, compare_models, plot_model, save_model, create_model, tune_model\n",
        ")\n",
        "\n",
        "print(\"ğŸš€ Initializing PyCaret Classification Environment...\")\n",
        "print(\"   GPU Mode: DISABLED (Intel OpenCL Issue)\")\n",
        "print(\"   Normalization: ENABLED\")\n",
        "print(\"   Session ID: 42 (Reproducibility)\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                    Description             Value\n",
            "0                    Session id                42\n",
            "1                        Target             Label\n",
            "2                   Target type            Binary\n",
            "3           Original data shape      (200000, 21)\n",
            "4        Transformed data shape      (200000, 21)\n",
            "5   Transformed train set shape      (140000, 21)\n",
            "6    Transformed test set shape       (60000, 21)\n",
            "7              Numeric features                20\n",
            "8                    Preprocess              True\n",
            "9               Imputation type            simple\n",
            "10           Numeric imputation              mean\n",
            "11       Categorical imputation              mode\n",
            "12                    Normalize              True\n",
            "13             Normalize method            zscore\n",
            "14               Fold Generator   StratifiedKFold\n",
            "15                  Fold Number                10\n",
            "16                     CPU Jobs                -1\n",
            "17                      Use GPU             False\n",
            "18               Log Experiment             False\n",
            "19              Experiment Name  clf-default-name\n",
            "20                          USI              e0c1\n"
          ]
        }
      ],
      "source": [
        "# Initialize PyCaret setup\n",
        "clf_setup = setup(\n",
        "    data=df_sample,\n",
        "    target=TARGET_COLUMN,\n",
        "    session_id=RANDOM_STATE,\n",
        "    n_jobs=-1,              # Use all CPU cores\n",
        "    use_gpu=False,          # GPU disabled to prevent LightGBM/Intel OpenCL crash\n",
        "    normalize=True,         # Apply scaling\n",
        "    log_experiment=False,   # Lightweight - no MLflow logging\n",
        "    verbose=True,           # Show setup information\n",
        "    html=False              # Disable HTML output for cleaner logs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš”ï¸  THE BATTLE BEGINS!\n",
            "============================================================\n",
            "Contenders:\n",
            "  1. LIGHTGBM\n",
            "  2. XGBOOST\n",
            "  3. CATBOOST\n",
            "  4. RF\n",
            "  5. ET\n",
            "  6. DT\n",
            "  7. ADA\n",
            "  8. GBC\n",
            "\n",
            "ğŸ“ Metrics: 5-Fold CV | Optimizing for F1 Score\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Define models to compare\n",
        "BATTLE_MODELS = [\n",
        "    'lightgbm',   # LightGBM - Fast gradient boosting\n",
        "    'xgboost',    # XGBoost - Extreme gradient boosting\n",
        "    'catboost',   # CatBoost - Categorical boosting\n",
        "    'rf',         # Random Forest\n",
        "    'et',         # Extra Trees\n",
        "    'dt',         # Decision Tree\n",
        "    'ada',        # AdaBoost\n",
        "    'gbc'         # Gradient Boosting Classifier\n",
        "]\n",
        "\n",
        "print(\"âš”ï¸  THE BATTLE BEGINS!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Contenders:\")\n",
        "for i, model in enumerate(BATTLE_MODELS, 1):\n",
        "    print(f\"  {i}. {model.upper()}\")\n",
        "print(\"\\nğŸ“ Metrics: 5-Fold CV | Optimizing for F1 Score\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ Starting model comparison (this may take several minutes)...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
            "et                 Extra Trees Classifier    0.9978  0.9989  0.9932  0.9943   \n",
            "xgboost         Extreme Gradient Boosting    0.9971  0.9999  0.9885  0.9951   \n",
            "lightgbm  Light Gradient Boosting Machine    0.9970  0.9998  0.9871  0.9959   \n",
            "rf               Random Forest Classifier    0.9970  0.9995  0.9883  0.9946   \n",
            "dt               Decision Tree Classifier    0.9970  0.9948  0.9914  0.9914   \n",
            "catboost              CatBoost Classifier    0.9966  0.9998  0.9854  0.9951   \n",
            "gbc          Gradient Boosting Classifier    0.9944  0.9988  0.9749  0.9928   \n",
            "ada                  Ada Boost Classifier    0.9845  0.9975  0.9307  0.9793   \n",
            "\n",
            "              F1   Kappa     MCC  TT (Sec)  \n",
            "et        0.9938  0.9925  0.9925     1.180  \n",
            "xgboost   0.9918  0.9900  0.9900     1.158  \n",
            "lightgbm  0.9915  0.9897  0.9897     1.130  \n",
            "rf        0.9914  0.9896  0.9896     3.096  \n",
            "dt        0.9914  0.9896  0.9896     0.494  \n",
            "catboost  0.9902  0.9882  0.9882     8.082  \n",
            "gbc       0.9838  0.9804  0.9804     8.268  \n",
            "ada       0.9543  0.9450  0.9454     1.930  \n",
            "\n",
            "============================================================\n",
            "ğŸ† CHAMPION SELECTED!\n",
            "   Best Model: ExtraTreesClassifier\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "# Run the comparison\n",
        "print(\"\\nğŸ Starting model comparison (this may take several minutes)...\\n\")\n",
        "\n",
        "best_model = compare_models(\n",
        "    include=BATTLE_MODELS,\n",
        "    fold=5,                 # 5-fold CV for speed\n",
        "    sort='F1',              # Optimize for F1 Score\n",
        "    n_select=1,             # Return only the best model\n",
        "    verbose=True            # Show progress\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ† CHAMPION SELECTED!\")\n",
        "print(f\"   Best Model: {type(best_model).__name__}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“Š Generating visualizations...\n",
            "   Output directory: D:\\Projects\\networkdetection\\networkdetection\\experiments\\results\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "print(\"ğŸ“Š Generating visualizations...\")\n",
        "print(f\"   Output directory: {RESULTS_DIR}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to save PyCaret plots\n",
        "def save_pycaret_plot(model, plot_type, filename):\n",
        "    \"\"\"\n",
        "    Generate and save PyCaret plot.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained PyCaret model\n",
        "        plot_type: Type of plot (e.g., 'confusion_matrix', 'auc', 'feature')\n",
        "        filename: Output filename (without extension)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # PyCaret's plot_model saves to current directory by default\n",
        "        plot_model(model, plot=plot_type, save=True)\n",
        "        \n",
        "        # Default name pattern used by PyCaret\n",
        "        default_name = f\"{plot_type.replace('_', ' ').title()}.png\"\n",
        "        \n",
        "        # Alternative patterns PyCaret might use\n",
        "        possible_names = [\n",
        "            default_name,\n",
        "            f\"{plot_type}.png\",\n",
        "            f\"{plot_type.title()}.png\",\n",
        "            \"Confusion Matrix.png\",\n",
        "            \"Feature Importance.png\",\n",
        "            \"AUC.png\"\n",
        "        ]\n",
        "        \n",
        "        # Find and move the generated file\n",
        "        for name in possible_names:\n",
        "            if os.path.exists(name):\n",
        "                target_path = RESULTS_DIR / filename\n",
        "                shutil.move(name, target_path)\n",
        "                print(f\"  âœ… Saved: {filename}\")\n",
        "                return target_path\n",
        "        \n",
        "        print(f\"  âš ï¸ Could not locate generated plot for {plot_type}\")\n",
        "        return None\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  âŒ Error generating {plot_type}: {str(e)}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Generating Confusion Matrix...\n",
            "  âœ… Saved: confusion_matrix.png\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "WindowsPath('D:/Projects/networkdetection/networkdetection/experiments/results/confusion_matrix.png')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate and save Confusion Matrix\n",
        "print(\"\\n Generating Confusion Matrix...\")\n",
        "save_pycaret_plot(best_model, 'confusion_matrix', 'confusion_matrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Generating Feature Importance...\n",
            "  âœ… Saved: feature_importance.png\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "WindowsPath('D:/Projects/networkdetection/networkdetection/experiments/results/feature_importance.png')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate and save Feature Importance\n",
        "print(\"\\n Generating Feature Importance...\")\n",
        "save_pycaret_plot(best_model, 'feature', 'feature_importance.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Generating ROC/AUC Curve...\n",
            "  âœ… Saved: auc.png\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "WindowsPath('D:/Projects/networkdetection/networkdetection/experiments/results/auc.png')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate and save AUC/ROC Curve\n",
        "print(\"\\n Generating ROC/AUC Curve...\")\n",
        "save_pycaret_plot(best_model, 'auc', 'auc.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Generated Artifacts:\n",
            "============================================================\n",
            "  ğŸ“Š auc.png\n",
            "  ğŸ“Š confusion_matrix.png\n",
            "  ğŸ“Š feature_importance.png\n"
          ]
        }
      ],
      "source": [
        "# Display generated visualizations\n",
        "print(\"\\n Generated Artifacts:\")\n",
        "print(\"=\" * 60)\n",
        "for f in RESULTS_DIR.glob('*.png'):\n",
        "    print(f\"  ğŸ“Š {f.name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Saving champion model...\n",
            "Transformation Pipeline and Model Successfully Saved\n",
            "\n",
            " Model saved to: D:\\Projects\\networkdetection\\networkdetection\\models\\pycaret_champion\n",
            "   File: pycaret_champion.pkl\n"
          ]
        }
      ],
      "source": [
        "# Save the champion model\n",
        "model_path = MODELS_DIR / 'pycaret_champion'\n",
        "\n",
        "print(\"\\n Saving champion model...\")\n",
        "save_model(best_model, str(model_path))\n",
        "print(f\"\\n Model saved to: {model_path}\")\n",
        "print(f\"   File: pycaret_champion.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘           BENCHMARK COMPLETE - SUMMARY                     â•‘\n",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
            "â•‘                                                              â•‘\n",
            "â•‘   Data Pipeline:                                           â•‘\n",
            "â•‘     â”œâ”€ Source: data/processed_randomforest/train.csv         â•‘\n",
            "â•‘     â”œâ”€ Original: ~1.3M+ samples                              â•‘\n",
            "â•‘     â””â”€ Stratified Sample: 200,000 samples                    â•‘\n",
            "â•‘                                                              â•‘\n",
            "â•‘    Battle Results:                                          â•‘\n",
            "â•‘     â”œâ”€ Algorithms Tested: 8                                  â•‘\n",
            "â•‘     â”œâ”€ Cross-Validation: 5-Fold                              â•‘\n",
            "â•‘     â”œâ”€ Primary Metric: F1 Score                              â•‘\n",
            "â•‘     â””â”€ Champion: ExtraTreesClassifier                â•‘\n",
            "â•‘                                                              â•‘\n",
            "â•‘   Artifacts Generated:                                     â•‘\n",
            "â•‘     â”œâ”€ experiments/results/confusion_matrix.png              â•‘\n",
            "â•‘     â”œâ”€ experiments/results/feature_importance.png            â•‘\n",
            "â•‘     â”œâ”€ experiments/results/auc.png                           â•‘\n",
            "â•‘     â””â”€ models/pycaret_champion.pkl                           â•‘\n",
            "â•‘                                                              â•‘\n",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
            "â•‘   Next Steps:                                               â•‘\n",
            "â•‘     1. Review metrics from compare_models() output           â•‘\n",
            "â•‘     2. Fine-tune hyperparameters with tune_model()           â•‘\n",
            "â•‘     3. Train on full dataset with identified architecture    â•‘\n",
            "â•‘     4. Evaluate on held-out test set                         â•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\"\"\n",
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "â•‘           BENCHMARK COMPLETE - SUMMARY                     â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘                                                              â•‘\n",
        "â•‘   Data Pipeline:                                           â•‘\n",
        "â•‘     â”œâ”€ Source: data/processed_randomforest/train.csv         â•‘\n",
        "â•‘     â”œâ”€ Original: ~1.3M+ samples                              â•‘\n",
        "â•‘     â””â”€ Stratified Sample: 200,000 samples                    â•‘\n",
        "â•‘                                                              â•‘\n",
        "â•‘    Battle Results:                                          â•‘\n",
        "â•‘     â”œâ”€ Algorithms Tested: 8                                  â•‘\n",
        "â•‘     â”œâ”€ Cross-Validation: 5-Fold                              â•‘\n",
        "â•‘     â”œâ”€ Primary Metric: F1 Score                              â•‘\n",
        "â•‘     â””â”€ Champion: {champion_name:<35} â•‘\n",
        "â•‘                                                              â•‘\n",
        "â•‘   Artifacts Generated:                                     â•‘\n",
        "â•‘     â”œâ”€ experiments/results/confusion_matrix.png              â•‘\n",
        "â•‘     â”œâ”€ experiments/results/feature_importance.png            â•‘\n",
        "â•‘     â”œâ”€ experiments/results/auc.png                           â•‘\n",
        "â•‘     â””â”€ models/pycaret_champion.pkl                           â•‘\n",
        "â•‘                                                              â•‘\n",
        "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
        "â•‘   Next Steps:                                               â•‘\n",
        "â•‘     1. Review metrics from compare_models() output           â•‘\n",
        "â•‘     2. Fine-tune hyperparameters with tune_model()           â•‘\n",
        "â•‘     3. Train on full dataset with identified architecture    â•‘\n",
        "â•‘     4. Evaluate on held-out test set                         â•‘\n",
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\"\"\".format(champion_name=type(best_model).__name__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Champion Model Details:\n",
            "============================================================\n",
            "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
            "                     criterion='gini', max_depth=None, max_features='sqrt',\n",
            "                     max_leaf_nodes=None, max_samples=None,\n",
            "                     min_impurity_decrease=0.0, min_samples_leaf=1,\n",
            "                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
            "                     monotonic_cst=None, n_estimators=100, n_jobs=-1,\n",
            "                     oob_score=False, random_state=42, verbose=0,\n",
            "                     warm_start=False)\n"
          ]
        }
      ],
      "source": [
        "# Display model info\n",
        "print(\"\\n Champion Model Details:\")\n",
        "print(\"=\" * 60)\n",
        "print(best_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
